{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network (Input1,Input2): #input1 : [Batch_size, 256, 256, 3], input2 : [Batch_size, 64, 64, 3]\n",
    "    \n",
    "    \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    \n",
    "    with tf.name_scope (\"Encoder\"):\n",
    "        \n",
    "        \n",
    "        \n",
    "        conv1_1 = tf.layers.conv2d(Input1, filters = 64, \n",
    "                                   kernel_size = 3, strides = 1, padding='SAME', \n",
    "                                   activation = tf.nn.relu, name = 'conv1_1') #[None, 256, 256, 64]\n",
    "        conv1_2 = tf.layers.conv2d(conv1_1, filters = 64, \n",
    "                                   kernel_size = 3, strides = 1, padding='SAME', \n",
    "                                   activation = tf.nn.relu, name = 'conv1_2') #[None, 256, 256, 64]\n",
    "        pool1 = tf.layers.max_pooling2d(conv1_2, pool_size = 2,\n",
    "                                   strides = 2, padding='SAME', name = 'pool1') #[None, 128, 128, 64]\n",
    "        \n",
    "        \n",
    "        \n",
    "        conv2_1 = tf.layers.conv2d(pool1, filters = 128, \n",
    "                                   kernel_size = 3, strides = 1, padding='SAME', \n",
    "                                   activation = tf.nn.relu, name = 'conv2_1')  #[None, 128, 128, 128]\n",
    "        conv2_2 = tf.layers.conv2d(conv2_1, filters = 128, \n",
    "                                   kernel_size = 3, strides = 1, padding='SAME', \n",
    "                                   activation = tf.nn.relu, name = 'conv2_2')  #[None, 128, 128, 128]\n",
    "        pool2 = tf.layers.max_pooling2d(conv2_2, pool_size = 2, \n",
    "                                   strides = 2, padding='SAME', name = 'pool2')  #[None, 64, 64, 128]\n",
    "        \n",
    "        \n",
    "        \n",
    "        conv3_1 = tf.layers.conv2d(pool2, filters = 256, kernel_size = 3, \n",
    "                                   strides = 1, padding='SAME', \n",
    "                                   activation = tf.nn.relu, name = 'conv3_1') #[None, 64, 64, 256]\n",
    "        conv3_2 = tf.layers.conv2d(conv3_1, filters = 256, \n",
    "                                   kernel_size = 3, strides = 1, padding='SAME', \n",
    "                                   activation = tf.nn.relu, name = 'conv3_2')  #[None, 64, 64, 256]\n",
    "        pool3 = tf.layers.max_pooling2d(conv3_2, pool_size = 2, \n",
    "                                   strides = 2, padding='SAME', name = 'pool3')  #[None, 32, 32, 256]\n",
    "        \n",
    "        \n",
    "        \n",
    "        conv4_1 = tf.layers.conv2d(pool3, filters = 512, kernel_size = 3, \n",
    "                                   strides = 1, padding='SAME', \n",
    "                                   activation = tf.nn.relu, name = 'conv4_1')  #[None, 32, 32, 512]\n",
    "        conv4_2 = tf.layers.conv2d(conv4_1, filters = 512, kernel_size = 3, \n",
    "                                   strides = 1, padding='SAME', \n",
    "                                   activation = tf.nn.relu, name = 'conv4_2')  #[None, 32, 32, 512]\n",
    "        pool4 = tf.layers.max_pooling2d(conv4_2, pool_size = 2, \n",
    "                                   strides = 2, padding='SAME', name = 'pool4')  #[None, 16, 16, 512]\n",
    "        \n",
    "        \n",
    "        \n",
    "        conv5_1 = tf.layers.conv2d(pool4, filters = 512, kernel_size = 3, \n",
    "                                   strides = 1, padding='SAME', \n",
    "                                   activation = tf.nn.relu, name = 'conv5_1')  #[None, 16, 16, 512]\n",
    "        conv5_2 = tf.layers.conv2d(conv5_1, filters = 512, kernel_size = 3, \n",
    "                                   strides = 1, padding='SAME', \n",
    "                                   activation = tf.nn.relu, name = 'conv5_2')  #[None, 16, 16, 512]\n",
    "        pool5 = tf.layers.max_pooling2d(conv5_2, pool_size = 2, \n",
    "                                   strides = 2, padding='SAME', name = 'pool5')  #[None, 8, 8, 512]\n",
    "        \n",
    "       \n",
    "        \n",
    "    with tf.name_scope(\"Conditional\"):\n",
    "        \n",
    "        \n",
    "        \n",
    "        Bconv1_1 = tf.layers.conv2d(Input2, filters = 32, kernel_size = 3, \n",
    "                                    strides = 1, padding='SAME', \n",
    "                                    activation = tf.nn.relu, name = 'Bconv1_1') #[None, 64, 64, 32]\n",
    "        Bconv1_2 = tf.layers.conv2d(Bconv1_1, filters = 32, kernel_size = 3, \n",
    "                                    strides = 1, padding='SAME', \n",
    "                                    activation = tf.nn.relu, name = 'Bconv1_2') #[None, 64, 64, 32]\n",
    "        Bpool1 = tf.layers.max_pooling2d(Bconv1_2, pool_size = 2, \n",
    "                                    strides = 2, padding='SAME', name = 'Bpool1')  #[None, 32, 32, 32]\n",
    "        \n",
    "        \n",
    "        \n",
    "        Bconv2_1 = tf.layers.conv2d(Bpool1, filters = 64, kernel_size = 3, \n",
    "                                    strides = 1, padding='SAME', \n",
    "                                    activation = tf.nn.relu, name = 'Bconv2_1')  #[None, 32, 32, 64]\n",
    "        Bconv2_2 = tf.layers.conv2d(Bconv2_1, filters = 64, kernel_size = 3, \n",
    "                                    strides = 1, padding='SAME', \n",
    "                                    activation = tf.nn.relu, name = 'Bconv2_2')  #[None, 32, 32, 64]\n",
    "        Bpool2 = tf.layers.max_pooling2d(Bconv2_2, pool_size = 2, \n",
    "                                    strides = 2, padding='SAME', name = 'Bpool2') #[None, 16, 16, 64]\n",
    "        \n",
    "        \n",
    "        \n",
    "        Bconv3_1 = tf.layers.conv2d(Bpool2, filters = 128, kernel_size = 3, \n",
    "                                    strides = 1, padding='SAME', \n",
    "                                    activation = tf.nn.relu, name = 'Bconv3_1')  #[None, 16, 16, 128]\n",
    "        Bpool3 = tf.layers.max_pooling2d(Bconv3_1, pool_size = 2, \n",
    "                                    strides = 2, padding='SAME', name = 'Bpool3')  #[None, 8, 8, 128]\n",
    "        \n",
    "        \n",
    "        \n",
    "        Bconv4_1 = tf.layers.conv2d(Bpool3, filters = 256, kernel_size = 3, \n",
    "                                    strides = 1, padding='SAME', \n",
    "                                    activation = tf.nn.relu, name = 'Bconv4_1')  #[None, 8, 8, 256]\n",
    "        Bpool4 = tf.layers.max_pooling2d(Bconv4_1, pool_size = 2, \n",
    "                                    strides = 2, padding='SAME', name = 'Bpool4')  #[None, 4, 4, 512]\n",
    "        \n",
    "        \n",
    "        \n",
    "        Bconv5_1 = tf.layers.conv2d(Bpool4, filters = 512, kernel_size = 3, \n",
    "                                    strides = 1, padding='SAME', \n",
    "                                    activation = tf.nn.relu, name = 'Bconv5_1')  #[None, 4, 4, 512]\n",
    "        Bpool5 = tf.layers.max_pooling2d(Bconv5_1, pool_size = 2, \n",
    "                                    strides = 2, padding='SAME', name = 'Bpool5')  #[None, 2, 2, 512]\n",
    "        \n",
    "        \n",
    "        Bconv6 = tf.layers.conv2d(Bpool5, filters = 512, kernel_size = 2, \n",
    "                                    strides = 1, activation = tf.nn.relu, name = 'Bconv6') #[None, 1, 1, 512]\n",
    "        \n",
    "        \n",
    "  \n",
    "        Btile1=tf.tile(Bconv6,[1,pool5.get_shape().as_list()[1],pool5.get_shape().as_list()[2],1])  #[None, 8, 8, 512]\n",
    "    \n",
    "        Btile2=tf.tile(Bconv6,[1,conv5_2.get_shape().as_list()[1],conv5_2.get_shape().as_list()[2],1]) #[None, 16, 16, 512]\n",
    "         \n",
    "        Btile3=tf.tile(Bconv6,[1,conv4_2.get_shape().as_list()[1],conv4_2.get_shape().as_list()[2],1])  #[None, 32, 32, 512]\n",
    "        \n",
    "        Btile4=tf.tile(Bconv6,[1,conv3_2.get_shape().as_list()[1],conv3_2.get_shape().as_list()[2],1])  #[None, 64, 64, 512]\n",
    "        \n",
    "        Btile5=tf.tile(Bconv6,[1,conv2_2.get_shape().as_list()[1],conv2_2.get_shape().as_list()[2],1])  #[None, 128, 128, 512]\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "    with tf.name_scope(\"Decoder\"):\n",
    "        \n",
    "        \n",
    "        \n",
    "        efused_1= tf.concat([pool5,Btile1],-1, name='efused_1')  #[None, 8, 8, 1024]\n",
    "        \n",
    "        Dconv1_1=tf.layers.conv2d_transpose(efused_1, filters=512, kernel_size=3, \n",
    "                                            padding='SAME', strides=1, \n",
    "                                            activation=tf.nn.relu, name='Dconv1_1')  #[None, 8, 8, 512]\n",
    "        \n",
    "        Dconv1_2=tf.layers.conv2d_transpose(Dconv1_1, filters=512, kernel_size=3, \n",
    "                                            padding='SAME', strides=1, \n",
    "                                            activation=tf.nn.relu, name='Dconv1_2')  #[None, 8, 8, 512]\n",
    "        \n",
    "        upsam1 = tf.image.resize_nearest_neighbor(Dconv1_2,size=(16,16))  #[None, 16, 16, 512]]\n",
    "     \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        efused_2= tf.concat([conv5_2,Btile2],-1, name='efused_2')  #[None, 16, 16, 1024]\n",
    "        \n",
    "        fconv_1 = tf.layers.conv2d(efused_2, filters = 512, kernel_size = 1, \n",
    "                                            strides = 1, padding='SAME', \n",
    "                                            activation = tf.nn.relu, name = 'fconv_1')  #[None, 16, 16, 512]\n",
    "        \n",
    "        dfused_2= tf.concat([upsam1 ,fconv_1],-1, name='dfused_2')  #[None, 16, 16, 1024]\n",
    "        \n",
    "        Dconv2_1=tf.layers.conv2d_transpose(dfused_2, filters=512, kernel_size=3, \n",
    "                                            padding='SAME', strides=1, \n",
    "                                            activation=tf.nn.relu, name='Dconv2_1')  #[None, 16, 16, 512]\n",
    "        \n",
    "        Dconv2_2=tf.layers.conv2d_transpose(Dconv2_1, filters=512, kernel_size=3, \n",
    "                                            padding='SAME', strides=1, \n",
    "                                            activation=tf.nn.relu, name='Dconv2_2')  #[None, 16, 16, 512]\n",
    "        \n",
    "        upsam2 = tf.image.resize_nearest_neighbor(Dconv2_2,size=(32,32))  #[None, 32, 32, 512]\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        efused_3= tf.concat([conv4_2,Btile3],-1, name='efused_3')  #[None, 32, 32, 1024]\n",
    "        \n",
    "        fconv_2 = tf.layers.conv2d(efused_3, filters = 256, kernel_size = 1, \n",
    "                                           strides = 1, padding='SAME', \n",
    "                                           activation = tf.nn.relu, name = 'fconv_2')  #[None, 32, 32, 256]\n",
    "        \n",
    "        dfused_3= tf.concat([upsam2 ,fconv_2],-1, name='dfused_3')  #[None, 32, 32, 768]\n",
    "        \n",
    "        Dconv3_1=tf.layers.conv2d_transpose(dfused_3, filters=256, kernel_size=3, \n",
    "                                            padding='SAME', strides=1, \n",
    "                                            activation=tf.nn.relu, name='Dconv3_1')  #[None, 32, 32, 256]\n",
    "        \n",
    "        Dconv3_2=tf.layers.conv2d_transpose(Dconv3_1, filters=256, kernel_size=3, \n",
    "                                            padding='SAME', strides=1, \n",
    "                                            activation=tf.nn.relu, name='Dconv3_2')  #[None, 32, 32, 256]\n",
    "        \n",
    "        upsam3 = tf.image.resize_nearest_neighbor(Dconv3_2,size=(64,64))  #[None, 64, 64, 256]\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        efused_4= tf.concat([conv3_2,Btile4],-1, name='efused_4')  #[None, 64, 64, 768]\n",
    "        \n",
    "        fconv_3 = tf.layers.conv2d(efused_4, filters = 128, kernel_size = 1, \n",
    "                                           strides = 1, padding='SAME', \n",
    "                                           activation = tf.nn.relu, name = 'fconv_3')  #[None, 64, 64, 128]\n",
    "        \n",
    "        dfused_4= tf.concat([upsam3 ,fconv_3],-1, name='dfused_4')  #[None, 64, 64, 384]\n",
    "        \n",
    "        Dconv4_1=tf.layers.conv2d_transpose(dfused_4, filters=128, kernel_size=3, \n",
    "                                            padding='SAME', strides=1, \n",
    "                                            activation=tf.nn.relu, name='Dconv4_1')  #[None, 64, 64, 128]\n",
    "        \n",
    "        Dconv4_2=tf.layers.conv2d_transpose(Dconv4_1, filters=128, kernel_size=3, \n",
    "                                            padding='SAME', strides=1, \n",
    "                                            activation=tf.nn.relu, name='Dconv4_2')  #[None, 64, 64, 128]\n",
    "        \n",
    "        upsam4 = tf.image.resize_nearest_neighbor(Dconv4_2,size=(128,128))  #[None, 128, 128, 128]\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        efused_5= tf.concat([conv2_2,Btile5],-1, name='efused_5')  #[None, 128, 128, 640]\n",
    "    \n",
    "        fconv_4 = tf.layers.conv2d(efused_5, filters = 64, kernel_size = 1, \n",
    "                                           strides = 1, padding='SAME', \n",
    "                                           activation = tf.nn.relu, name = 'fconv_4')  #[None, 128, 128, 64]\n",
    "        \n",
    "        dfused_5= tf.concat([upsam4 ,fconv_4],-1, name='dfused_5')  #[None, 128, 128, 192]\n",
    "        \n",
    "        Dconv5_1=tf.layers.conv2d_transpose(dfused_5, filters=64, kernel_size=3, \n",
    "                                           padding='SAME', strides=1, \n",
    "                                           activation=tf.nn.relu, name='Dconv5_1')  #[None, 128, 128, 64]\n",
    "        \n",
    "        Dconv5_2=tf.layers.conv2d_transpose(Dconv5_1, filters=64, kernel_size=3, \n",
    "                                           padding='SAME', strides=1, \n",
    "                                           activation=tf.nn.relu, name='Dconv5_2')  #[None, 128, 128, 64]\n",
    "        \n",
    "        upsam5 = tf.image.resize_nearest_neighbor(Dconv5_2,size=(256,256))  #[None, 256, 256, 64]\n",
    "        \n",
    "        \n",
    "        output=tf.layers.conv2d_transpose(upsam5, filters=1, kernel_size=3, \n",
    "                                           padding='SAME', strides=1, \n",
    "                                           activation=tf.nn.relu, name='fconv_5')  #[None, 256, 256, 1]\n",
    "        \n",
    "      \n",
    "    \n",
    "    output = tf.identity(output, 'Output')\n",
    "        \n",
    "        \n",
    "    trainwriter = tf.summary.FileWriter(\"/content/logs\", sess.graph)\n",
    "        \n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "\n",
    "Input1=tf.placeholder(dtype = tf.float32, shape = [None, 256, 256, 3], name = 'Target')\n",
    "Input2=tf.placeholder(dtype = tf.float32, shape = [None, 64, 64, 3], name = 'Query')\n",
    "\n",
    "\n",
    "Output = Network(Input1,Input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
